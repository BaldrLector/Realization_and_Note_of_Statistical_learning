{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVM\n",
    "\n",
    ">- 线性可分 or 线性不可分\n",
    ">\n",
    ">- 对偶问题\n",
    ">\n",
    ">- 间隔最大化\n",
    ">\n",
    ">- hinge loss\n",
    ">\n",
    ">- 核技巧\n",
    ">\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意这里为了不失一般性，我们用了CS231n的多分类SVM\n",
    ">[CS231n SVM](http://cs231n.github.io/linear-classify/)\n",
    ">$$Hinge\\ loss = \\max(0,s_j - s_{y_i}+\\Delta)$$\n",
    "这里的$\\Delta$常常取1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class svm(object):\n",
    "    def __init__(self):\n",
    "        # W : D,C\n",
    "        self.W=None\n",
    "    \n",
    "    def predict(self,X):\n",
    "        y_pred=np.zeros(X.shape[1])\n",
    "        y_pred=np.argmax(np.dot(X,self.W),axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    def train(self,X,y,learning_rate=1e-3,reg=1e-5,num_inters=1000,batch_size=200,verbose=False):\n",
    "        # X: N,D\n",
    "        # Y: N,\n",
    "        num_train,dim=X.shape\n",
    "        num_class=len(set(y))\n",
    "        \n",
    "        if self.W is None:\n",
    "            self.W=0.001 * np.random.randn(X.shape[1],num_class)\n",
    "        \n",
    "        loss_history=[]\n",
    "        for it in range(num_iters):\n",
    "            indice=np.random.choice(num_train,batch_size)\n",
    "            X_batch,y_batch=X[indice],y[indice]\n",
    "            \n",
    "            loss,grad=self.svmLoss(X_batch,y_batch,reg)\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            self.W-=learning_rate*grad\n",
    "        return loss_history\n",
    "    \n",
    "    # 向量化的写法\n",
    "    def svmLoss(self,X,y,reg):\n",
    "        dw=np.zeros_like(self.W)\n",
    "        num_train,dim=X.shape\n",
    "        num_class=len(set(y))\n",
    "        \n",
    "        loss=0.0\n",
    "        scores=X.dot(self.W)  #scroes : N,C\n",
    "        margin = scores-scores[range(0,X.shape[0]),y].reshape(-1,1)+1\n",
    "        margin[range(X.shape[0],y)]=0\n",
    "        margin=(margin>0)*margin\n",
    "        loss+=margin.sum()/num_train\n",
    "        loss+=0.5*reg*np.sum(self.W**2)\n",
    "        \n",
    "        counts=(margin>0).astype(int)\n",
    "        counts[range(num_train),y]-=np.sum(counts,axis=1)\n",
    "        dW+=np.dot(X.T,counts)/N+reg*self.W\n",
    "        \n",
    "        return loss,dw\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
